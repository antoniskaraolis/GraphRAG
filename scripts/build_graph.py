# -*- coding: utf-8 -*-
"""build_graph.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ctOM-87k5m3gYQjt0ak79fZ6RrzOwzH9
"""

#!/usr/bin/env python3
# scripts/build_graph.py
import networkx as nx
from graphrag.data_processing import prepare_dataset, process_papers
from graphrag.graph import build_graph
from graphrag.embeddings import add_embeddings
from graphrag.clustering import cluster_papers, cluster_authors

# Configuration
TARGETS = {
    "Computer Science": 0.125,
    "Economics": 0.125,
    "Electrical Engineering and Systems Science": 0.125,
    "Mathematics": 0.125,
    "Physics": 0.125,
    "Quantitative Biology": 0.125,
    "Quantitative Finance": 0.125,
    "Statistics": 0.125
}
TOTAL_PAPERS = 300

if __name__ == "__main__":
    # Step 1: Prepare dataset
    input_data = "data/raw/arxiv_data.json"
    sampled_data = "data/processed/subset_categorised_data.json"
    print("Preparing dataset...")
    prepare_dataset(input_data, sampled_data, TARGETS, TOTAL_PAPERS)

    # Step 2: Process into CSV
    print("Processing papers into CSV...")
    csv_files = process_papers(sampled_data, "data/processed/graph_data")

    # Step 3: Build graph
    print("Building graph...")
    G = build_graph(csv_files)

    # Step 4: Add embeddings
    print("Adding embeddings...")
    G = add_embeddings(G)

    # Step 5: Cluster
    print("Clustering papers...")
    G = cluster_papers(G)
    print("Clustering authors...")
    G = cluster_authors(G, method='hybrid')

    # Save graph
    output_path = "data/processed/graph.graphml"
    nx.write_graphml(G, output_path)
    print(f"Graph saved to {output_path}")
    print(f"Graph contains {len(G.nodes)} nodes and {len(G.edges)} edges")